{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25233a01-337d-49f0-a9c5-fdbcdaae334b",
   "metadata": {},
   "source": [
    "# Smolagents\n",
    "\n",
    "In this notebook we will build two agents using [smolagents](https://github.com/huggingface/smolagents).\n",
    "\n",
    "Hints: To make the second agent work, you need to configure an `SERPAPI_API_KEY` environment variable. You can create such a key on [https://serpapi.com/](https://serpapi.com/) - for free at the time of writing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0101739-6302-4acb-94c0-dee40ea7e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\miniforge3\\envs\\genai-gpu\\Lib\\site-packages\\pydantic\\_internal\\_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from smolagents.agents import ToolCallingAgent\n",
    "from smolagents import tool, LiteLLMModel\n",
    "from smolagents.default_tools import GoogleSearchTool\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ea7bc-e770-429b-86f0-7ba0932f7326",
   "metadata": {},
   "source": [
    "Under the hood, we use the [litellm](https://github.com/BerriAI/litellm) library to access a local or remote open-weight LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a434cef-f107-4acc-9d19-278e699c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LiteLLMModel(model_id=\"openai/llama3.2\", \n",
    "                     api_base=\"http://localhost:11434/v1\", # replace with remote open-ai compatible server if necessary\n",
    "                     api_key=\"your-api-key\")               # replace with API key if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda56262-2be2-4730-998d-51048dbd1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will work after the next release of smolagents > 0.1.3, as this PR was merged: https://github.com/huggingface/smolagents/pull/10\n",
    "model = LiteLLMModel(model_id=\"openai/meta-llama/Llama-3.3-70B-Instruct\", \n",
    "                     api_base=\"https://llm.scads.ai/v1\", \n",
    "                 api_key=os.environ.get('SCADSAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31e3c9-cbd9-4bb0-9885-483049c57b5e",
   "metadata": {},
   "source": [
    "## A custom agent\n",
    "First we demonstrate how to configure a custom function so that it can be called by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53f520f-3dee-4b27-b6f5-4b3c86f082f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def read_arxiv_paper(arxiv_url:str)-> str:\n",
    "    \"\"\"Read the abstract of an arxiv-paper and return most important contents as markdown.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_url: url of the arxiv paper to read.\n",
    "    \"\"\"\n",
    "    from agent_tools import get_arxiv_metadata\n",
    "    arxiv_id = arxiv_url.split(\"/\")[-1]\n",
    "    metadata = get_arxiv_metadata(arxiv_id)\n",
    "    title = metadata[\"title\"]\n",
    "    summary = metadata[\"summary\"]\n",
    "    authors = \", \".join(metadata[\"authors\"])\n",
    "    \n",
    "    return f\"\"\"## {title}\n",
    "By {authors}\n",
    "\n",
    "{summary}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9edbd746-7b44-4b66-b152-7c6cf1efd173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Read this paper and tell me its most important points: https://arxiv.org/abs/2301.00303v1</span>                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - openai/meta-llama/Llama-3.3-70B-Instruct ───────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mRead this paper and tell me its most important points: https://arxiv.org/abs/2301.00303v1\u001b[0m                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - openai/meta-llama/Llama-3.3-70B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'read_arxiv_paper' with arguments: {'arxiv_url': 'https://arxiv.org/abs/2301.00303v1'}            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'read_arxiv_paper' with arguments: {'arxiv_url': 'https://arxiv.org/abs/2301.00303v1'}            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: ## Rethinking with Retrieval: Faithful Large Language Model Inference\n",
       "By Hangfeng He, Hongming Zhang, Dan Roth\n",
       "\n",
       "Despite the success of large language models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span> in various natural\n",
       "language processing <span style=\"font-weight: bold\">(</span>NLP<span style=\"font-weight: bold\">)</span> tasks, the stored knowledge in these models may\n",
       "inevitably be incomplete, out-of-date, or incorrect. This motivates the need to\n",
       "utilize external knowledge to assist LLMs. Unfortunately, current methods for\n",
       "incorporating external knowledge often require additional training or\n",
       "fine-tuning, which can be costly and may not be feasible for LLMs. To address\n",
       "this issue, we propose a novel post-processing approach, rethinking with\n",
       "retrieval <span style=\"font-weight: bold\">(</span>RR<span style=\"font-weight: bold\">)</span>, which retrieves relevant external knowledge based on the\n",
       "decomposed reasoning steps obtained from the chain-of-thought <span style=\"font-weight: bold\">(</span>CoT<span style=\"font-weight: bold\">)</span> prompting.\n",
       "This lightweight approach does not require additional training or fine-tuning\n",
       "and is not limited by the input length of LLMs. We evaluate the effectiveness\n",
       "of RR through extensive experiments with GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> on three complex reasoning\n",
       "tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\n",
       "results show that RR can produce more faithful explanations and improve the\n",
       "performance of LLMs.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: ## Rethinking with Retrieval: Faithful Large Language Model Inference\n",
       "By Hangfeng He, Hongming Zhang, Dan Roth\n",
       "\n",
       "Despite the success of large language models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m in various natural\n",
       "language processing \u001b[1m(\u001b[0mNLP\u001b[1m)\u001b[0m tasks, the stored knowledge in these models may\n",
       "inevitably be incomplete, out-of-date, or incorrect. This motivates the need to\n",
       "utilize external knowledge to assist LLMs. Unfortunately, current methods for\n",
       "incorporating external knowledge often require additional training or\n",
       "fine-tuning, which can be costly and may not be feasible for LLMs. To address\n",
       "this issue, we propose a novel post-processing approach, rethinking with\n",
       "retrieval \u001b[1m(\u001b[0mRR\u001b[1m)\u001b[0m, which retrieves relevant external knowledge based on the\n",
       "decomposed reasoning steps obtained from the chain-of-thought \u001b[1m(\u001b[0mCoT\u001b[1m)\u001b[0m prompting.\n",
       "This lightweight approach does not require additional training or fine-tuning\n",
       "and is not limited by the input length of LLMs. We evaluate the effectiveness\n",
       "of RR through extensive experiments with GPT-\u001b[1;36m3\u001b[0m on three complex reasoning\n",
       "tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\n",
       "results show that RR can produce more faithful explanations and improve the\n",
       "performance of LLMs.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 2.67 seconds| Input tokens: 1,280 | Output tokens: 35]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 2.67 seconds| Input tokens: 1,280 | Output tokens: 35]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"The most important points of the paper 'Rethinking     │\n",
       "│ with Retrieval: Faithful Large Language Model Inference' are: it proposes a novel post-processing approach      │\n",
       "│ called rethinking with retrieval (RR) to utilize external knowledge to assist large language models (LLMs), RR  │\n",
       "│ retrieves relevant external knowledge based on decomposed reasoning steps obtained from chain-of-thought (CoT)  │\n",
       "│ prompting, and it does not require additional training or fine-tuning. The paper evaluates the effectiveness of │\n",
       "│ RR through experiments with GPT-3 on three complex reasoning tasks and shows that RR can produce more faithful  │\n",
       "│ explanations and improve the performance of LLMs.\"}                                                             │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"The most important points of the paper 'Rethinking     │\n",
       "│ with Retrieval: Faithful Large Language Model Inference' are: it proposes a novel post-processing approach      │\n",
       "│ called rethinking with retrieval (RR) to utilize external knowledge to assist large language models (LLMs), RR  │\n",
       "│ retrieves relevant external knowledge based on decomposed reasoning steps obtained from chain-of-thought (CoT)  │\n",
       "│ prompting, and it does not require additional training or fine-tuning. The paper evaluates the effectiveness of │\n",
       "│ RR through experiments with GPT-3 on three complex reasoning tasks and shows that RR can produce more faithful  │\n",
       "│ explanations and improve the performance of LLMs.\"}                                                             │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: The most important points of the paper 'Rethinking with Retrieval: Faithful Large Language Model </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Inference' are: it proposes a novel post-processing approach called rethinking with retrieval (RR) to utilize </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">external knowledge to assist large language models (LLMs), RR retrieves relevant external knowledge based on </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">decomposed reasoning steps obtained from chain-of-thought (CoT) prompting, and it does not require additional </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">training or fine-tuning. The paper evaluates the effectiveness of RR through experiments with GPT-3 on three </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">complex reasoning tasks and shows that RR can produce more faithful explanations and improve the performance of </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">LLMs.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: The most important points of the paper 'Rethinking with Retrieval: Faithful Large Language Model \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mInference' are: it proposes a novel post-processing approach called rethinking with retrieval (RR) to utilize \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mexternal knowledge to assist large language models (LLMs), RR retrieves relevant external knowledge based on \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdecomposed reasoning steps obtained from chain-of-thought (CoT) prompting, and it does not require additional \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtraining or fine-tuning. The paper evaluates the effectiveness of RR through experiments with GPT-3 on three \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcomplex reasoning tasks and shows that RR can produce more faithful explanations and improve the performance of \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mLLMs.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 5.86 seconds| Input tokens: 2,885 | Output tokens: 176]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 5.86 seconds| Input tokens: 2,885 | Output tokens: 176]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The most important points of the paper 'Rethinking with Retrieval: Faithful Large Language Model Inference' are: it proposes a novel post-processing approach called rethinking with retrieval (RR) to utilize external knowledge to assist large language models (LLMs), RR retrieves relevant external knowledge based on decomposed reasoning steps obtained from chain-of-thought (CoT) prompting, and it does not require additional training or fine-tuning. The paper evaluates the effectiveness of RR through experiments with GPT-3 on three complex reasoning tasks and shows that RR can produce more faithful explanations and improve the performance of LLMs.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = ToolCallingAgent(tools=[read_arxiv_paper], model=model)\n",
    "\n",
    "agent.run(\"Read this paper and tell me its most important points: https://arxiv.org/abs/2301.00303v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fd582-7dcd-40e3-b644-5839bef1936e",
   "metadata": {},
   "source": [
    "## A search agent\n",
    "Next, we use predefined tools, such as a tool for searching the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e37dd3-5b5f-42f5-bdd9-5faf1f671778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">What does ScaDS.AI do?</span>                                                                                          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - openai/meta-llama/Llama-3.3-70B-Instruct ───────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhat does ScaDS.AI do?\u001b[0m                                                                                          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - openai/meta-llama/Llama-3.3-70B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'filter_year': 2024, 'query': 'ScaDS.AI'}                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'filter_year': 2024, 'query': 'ScaDS.AI'}                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: ## Search Results\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>. <span style=\"font-weight: bold\">[</span>Events and Event Series - ScaDS.AI Dresden/Leipzig<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/event/)</span>\n",
       "Date published: Jul <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig regularly organizes interesting events and event series on Artificial Intelligence.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. <span style=\"font-weight: bold\">[</span>Master's Seminar ScaDS.AI<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/education/masters-seminar-scads-ai/)</span>\n",
       "Date published: Aug <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "Participation in the “Master's Seminar ScaDS.AI” module enables students to familiarize themselves with current \n",
       "research topics at ScaDS.AI.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. <span style=\"font-weight: bold\">[</span>ScaDS.AI and ZIH at SC24 in Atlanta, Georgia<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/sc24/)</span>\n",
       "Date published: Nov <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "From <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>-.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.11</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>, ScaDS.AI Dresden/Leipzig &amp; ZIH represented the Center for Interdisciplinary Digital Sciences \n",
       "<span style=\"font-weight: bold\">(</span>CIDS<span style=\"font-weight: bold\">)</span> at SC24 in Atlanta.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. <span style=\"font-weight: bold\">[</span>ScaDS.AI Dresden/Leipzig<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://tu-dresden.de/cids/departments/scads-ai?set_language=en)</span>\n",
       "Date published: Nov <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: TU Dresden\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig is a competence center for AI, Data Science, &amp; Big Data with locations in Dresden and \n",
       "Leipzig.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. <span style=\"font-weight: bold\">[</span>Summer School <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/event/summer-schools/summer-school-2024/)</span>\n",
       "Date published: Jun <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "The 10th International Summer School on AI and Big Data will be hosted from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.06</span> – <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.06</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span> by ScaDS.AI in \n",
       "Leipzig.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. <span style=\"font-weight: bold\">[</span>General Assembly Meeting in March <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/general-assembly-meeting-march-2024/)</span>\n",
       "Date published: Mar <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig organized the first General Assembly Meeting of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>. More than <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span> participants joined \n",
       "the event in Dresden.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. <span style=\"font-weight: bold\">[</span>ScaDS.AI Dresden/Leipzig<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.linkedin.com/company/scads-ai)</span>\n",
       "Source: LinkedIn · ScaDS.AI Dresden/Leipzig\n",
       "\n",
       "ScaDS.AI <span style=\"font-weight: bold\">(</span>Center for Scalable Data Analytics and Artificial Intelligence<span style=\"font-weight: bold\">)</span> Dresden/Leipzig is a center for Data \n",
       "Science, Artificial Intelligence and Big Data <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. <span style=\"font-weight: bold\">[</span>Projects<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/research/architectures-scalability-security/projects/)</span>\n",
       "Date published: Jul <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "A center for Data Science, Artificial Intelligence and Big Data with locations in Dresden and Leipzig.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>. <span style=\"font-weight: bold\">[</span>NAIC: AI as a Study Coach <span style=\"font-weight: bold\">(</span>Podcast<span style=\"font-weight: bold\">)](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scads.ai/naic-ai-as-a-study-coach/)</span>\n",
       "Date published: Nov <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>\n",
       "Source: ScaDS.AI\n",
       "\n",
       "The Junior Research Group NAIC of ScaDS.AI is investigating how chatbots can help students manage their academic \n",
       "life. NAIC stands for “Needs-Oriented AI <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: ## Search Results\n",
       "\u001b[1;36m0\u001b[0m. \u001b[1m[\u001b[0mEvents and Event Series - ScaDS.AI Dresden/Leipzig\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/event/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Jul \u001b[1;36m15\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig regularly organizes interesting events and event series on Artificial Intelligence.\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. \u001b[1m[\u001b[0mMaster's Seminar ScaDS.AI\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/education/masters-seminar-scads-ai/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Aug \u001b[1;36m20\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "Participation in the “Master's Seminar ScaDS.AI” module enables students to familiarize themselves with current \n",
       "research topics at ScaDS.AI.\n",
       "\n",
       "\u001b[1;36m2\u001b[0m. \u001b[1m[\u001b[0mScaDS.AI and ZIH at SC24 in Atlanta, Georgia\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/sc24/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Nov \u001b[1;36m22\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "From \u001b[1;36m17\u001b[0m-.\u001b[1;36m22.11\u001b[0m.\u001b[1;36m2024\u001b[0m, ScaDS.AI Dresden/Leipzig & ZIH represented the Center for Interdisciplinary Digital Sciences \n",
       "\u001b[1m(\u001b[0mCIDS\u001b[1m)\u001b[0m at SC24 in Atlanta.\n",
       "\n",
       "\u001b[1;36m3\u001b[0m. \u001b[1m[\u001b[0mScaDS.AI Dresden/Leipzig\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://tu-dresden.de/cids/departments/scads-ai?\u001b[0m\u001b[4;94mset_language\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94men\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Nov \u001b[1;36m27\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: TU Dresden\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig is a competence center for AI, Data Science, & Big Data with locations in Dresden and \n",
       "Leipzig.\n",
       "\n",
       "\u001b[1;36m4\u001b[0m. \u001b[1m[\u001b[0mSummer School \u001b[1;36m2024\u001b[0m\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/event/summer-schools/summer-school-2024/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Jun \u001b[1;36m28\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "The 10th International Summer School on AI and Big Data will be hosted from \u001b[1;36m25.06\u001b[0m – \u001b[1;36m28.06\u001b[0m.\u001b[1;36m2024\u001b[0m by ScaDS.AI in \n",
       "Leipzig.\n",
       "\n",
       "\u001b[1;36m5\u001b[0m. \u001b[1m[\u001b[0mGeneral Assembly Meeting in March \u001b[1;36m2024\u001b[0m\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/general-assembly-meeting-march-2024/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Mar \u001b[1;36m19\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "ScaDS.AI Dresden/Leipzig organized the first General Assembly Meeting of \u001b[1;36m2024\u001b[0m. More than \u001b[1;36m170\u001b[0m participants joined \n",
       "the event in Dresden.\n",
       "\n",
       "\u001b[1;36m6\u001b[0m. \u001b[1m[\u001b[0mScaDS.AI Dresden/Leipzig\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.linkedin.com/company/scads-ai\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Source: LinkedIn · ScaDS.AI Dresden/Leipzig\n",
       "\n",
       "ScaDS.AI \u001b[1m(\u001b[0mCenter for Scalable Data Analytics and Artificial Intelligence\u001b[1m)\u001b[0m Dresden/Leipzig is a center for Data \n",
       "Science, Artificial Intelligence and Big Data \u001b[33m...\u001b[0m\n",
       "\n",
       "\u001b[1;36m7\u001b[0m. \u001b[1m[\u001b[0mProjects\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/research/architectures-scalability-security/projects/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Jul \u001b[1;36m15\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "A center for Data Science, Artificial Intelligence and Big Data with locations in Dresden and Leipzig.\n",
       "\n",
       "\u001b[1;36m8\u001b[0m. \u001b[1m[\u001b[0mNAIC: AI as a Study Coach \u001b[1m(\u001b[0mPodcast\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scads.ai/naic-ai-as-a-study-coach/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Date published: Nov \u001b[1;36m8\u001b[0m, \u001b[1;36m2024\u001b[0m\n",
       "Source: ScaDS.AI\n",
       "\n",
       "The Junior Research Group NAIC of ScaDS.AI is investigating how chatbots can help students manage their academic \n",
       "life. NAIC stands for “Needs-Oriented AI \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 4.50 seconds| Input tokens: 1,311 | Output tokens: 28]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 4.50 seconds| Input tokens: 1,311 | Output tokens: 28]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"ScaDS.AI is a competence center for AI, Data Science,  │\n",
       "│ &amp; Big Data with locations in Dresden and Leipzig. It organizes events and event series on Artificial            │\n",
       "│ Intelligence, offers educational programs such as master's seminars, and conducts research in areas like        │\n",
       "│ scalable data analytics and artificial intelligence.\"}                                                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"ScaDS.AI is a competence center for AI, Data Science,  │\n",
       "│ & Big Data with locations in Dresden and Leipzig. It organizes events and event series on Artificial            │\n",
       "│ Intelligence, offers educational programs such as master's seminars, and conducts research in areas like        │\n",
       "│ scalable data analytics and artificial intelligence.\"}                                                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: ScaDS.AI is a competence center for AI, Data Science, &amp; Big Data with locations in Dresden and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Leipzig. It organizes events and event series on Artificial Intelligence, offers educational programs such as </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">master's seminars, and conducts research in areas like scalable data analytics and artificial intelligence.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: ScaDS.AI is a competence center for AI, Data Science, & Big Data with locations in Dresden and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mLeipzig. It organizes events and event series on Artificial Intelligence, offers educational programs such as \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmaster's seminars, and conducts research in areas like scalable data analytics and artificial intelligence.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.17 seconds| Input tokens: 3,353 | Output tokens: 101]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.17 seconds| Input tokens: 3,353 | Output tokens: 101]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaDS.AI is a competence center for AI, Data Science, & Big Data with locations in Dresden and Leipzig. It organizes events and event series on Artificial Intelligence, offers educational programs such as master's seminars, and conducts research in areas like scalable data analytics and artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = ToolCallingAgent(tools=[GoogleSearchTool()], model=model)\n",
    "\n",
    "print(agent.run(\"What does ScaDS.AI do?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85660066-3d95-4a57-aa69-146589065880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
