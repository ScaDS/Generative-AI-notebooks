{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2f5b58-9e18-4c5a-9cf7-157a71c82cf2",
   "metadata": {},
   "source": [
    "# PowerPoint Karaoke about Arxiv papers\n",
    "In this notebook we program an agent that is capable of generating PowerPoint slide decks out of Arxiv papers.\n",
    "\n",
    "We will use the [ScaDS.AI LLM infrastructure](https://llm.scads.ai/) infrastructure at the [Center for Information Services and High Performance Computing (ZIH) of TU Dresden](https://tu-dresden.de/zih). To use it, you must be connected via [TU Dresden VPN](https://tu-dresden.de/zih/dienste/service-katalog/arbeitsumgebung/zugang_datennetz/vpn) and have your API key stored in a `SCADSAI_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e08d14-4b62-4995-98b2-c8ebc9ad3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core.tools import FunctionTool\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from arxiv_utilities import convert_to_markdown, search_arxiv, download_pdf, pdf_to_markdown, make_powerpoint_slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7397cb8-2f95-4bcb-9939-394efc29b729",
   "metadata": {},
   "source": [
    "First, we initialize the LLM. The server supports the OpenAI-API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94df8374-311f-411a-91af-972fbebde9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILike(model=\"meta-llama/Llama-3.3-70B-Instruct\", \n",
    "                 request_timeout=120.0, \n",
    "                 api_base=\"https://llm.scads.ai/v1\", \n",
    "                 api_key=os.environ.get('SCADSAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7719e892-177a-4b80-800c-9da41326755b",
   "metadata": {},
   "source": [
    "Next, we specify tools. The actual functionality is programmed in [arxiv_utilities.py](arxiv_utilities.py). Note: To make these functions work, they require detailed docstrings describing precisely what parameters the functions require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20164efd-2b4a-42e3-b05d-1c25a4253303",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "\n",
    "@tools.append\n",
    "def search_publications(query=None, author=None, year=None, max_results=10):\n",
    "    \"\"\"Searches the arxiv for papers using a query, selects papers from given authors and/or by year.\"\"\"\n",
    "    papers = search_arxiv(query=query, author=author, year=year, max_results=max_results)\n",
    "    markdown = convert_to_markdown(papers)\n",
    "    return markdown\n",
    "\n",
    "@tools.append\n",
    "def download_paper(paper_link):\n",
    "    \"\"\"Downloads a paper and return its contents as markdown.\"\"\"\n",
    "    filename = download_pdf(paper_link)\n",
    "\n",
    "    if filename is not None:\n",
    "        return pdf_to_markdown(filename)\n",
    "\n",
    "# You can also add external tools like this.\n",
    "tools.append(make_powerpoint_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec543c89-4743-415b-8bc7-fd8a00964ec3",
   "metadata": {},
   "source": [
    "We can then initialize the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf93ba3-9116-492d-bb26-0e9ea9a90c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([FunctionTool.from_defaults(fn=t) for t in tools], llm=llm, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b25b2e-e3dd-4be3-a517-b2794ebf5b6b",
   "metadata": {},
   "source": [
    "Using this small helper function, we can ask the agent and will read its output as properly formatted markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3082551e-c469-4470-baea-746752e5e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    response = agent.chat(query)\n",
    "    display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05188920-a507-4f65-9188-eea961ed1ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "PDF downloaded: [http://arxiv.org/abs/2301.00303v1](pdf_filename), licensed CC-BY 4.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The powerpoint slide deck about the paper \"Rethinking with Retrieval: Faithful Large Language Model Inference\" has been created and saved as slides.pptx. The slide deck includes the title of the paper, the authors, and a link to the paper, as well as slides about the introduction, method, experiments, and conclusion of the paper."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat(\"\"\"\n",
    "I need to give a presentation about the latest arxiv paper from the year 2022 that was about LLMs.\n",
    "Please make a powerpoint slide deck about this paper.\n",
    "The first slide should have the same title as the paper, and mention the authors, and give a link to the paper.\n",
    "The following slides are about the individual chapters of the paper.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25732b-daae-4e5e-b90c-a3f9129c543b",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "The following language models are available on the Server. Find out which of those are capable of generating a slide deck.\n",
    "E.g. run the prompt above for every LLM 10 times and count how often a pptx file is created.\n",
    "\n",
    "Hints: \n",
    "* You may have to specify the pptx filename to make this work.\n",
    "* To see what the agent is doing under the hood, consider setting `verbose=True`.\n",
    "\n",
    "Available models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12a4dd4-d43a-49f5-b705-9681fd02da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "Qwen/Qwen2-VL-7B-Instruct\n",
      "de-en-translator\n",
      "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\n",
      "openGPT-X/Teuken-7B-instruct-research-v0.4\n",
      "CohereForAI/c4ai-command-r-08-2024\n",
      "meta-llama/Llama-3.3-70B-Instruct\n",
      "Qwen/QwQ-32B-Preview\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(base_url=\"https://llm.scads.ai/v1\",\n",
    "                       api_key=os.environ.get('SCADSAI_API_KEY'))\n",
    "\n",
    "print(\"\\n\".join([model.id for model in client.models.list().data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672e274-1709-4f57-bdb8-eb2d320f3c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
