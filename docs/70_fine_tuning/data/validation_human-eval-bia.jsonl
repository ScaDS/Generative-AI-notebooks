{"task_id": "../test_cases/apply_otsu_threshold_and_count_postiive_pixels.ipynb", "prompt": "def apply_otsu_threshold_and_count_postiive_pixels(image):\n    \"\"\"\n    Takes an image, applies Otsu's threshold method to it to create a binary image and \n    counts the positive pixels.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "entry_point": "apply_otsu_threshold_and_count_postiive_pixels", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,1,1,0,0],\n        [1,1,1,0,0],\n        [1,0,0,0,0],\n        [0,0,0,1,0],\n    ])) == 8\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [1,2,1,0,0],\n        [0,1,3,4,0],\n        [0,1,4,1,0],\n    ])) == 4\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 0"}
{"task_id": "../test_cases/bland_altman.ipynb", "prompt": "def bland_altman(dataframe, column1:str, column2:str):\n    \"\"\"\n    Takes two specified columns from a given dataframe and applies Bland-Altman-Analysis to them.\n    Therefore, it adds two new columns, one called 'mean' containing the mean of the two corresponding values,\n    and one called 'diff' containing the difference between the two.\n    \"\"\"", "canonical_solution": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "entry_point": "bland_altman", "test": "def check(candidate):\n    import pandas as pd\n    import numpy as np\n    df = pd.DataFrame(\n        {\n         'a':[1,2,3,0],\n         'b':[2,2,3,6]\n        }\n    )\n\n    candidate(df, 'a', 'b')\n\n    assert len(df.columns) == 4\n    \n    mean_column = df['mean']\n    diff_column = df['diff']\n    \n    assert np.array_equal([1.5, 2, 3, 3], mean_column)\n    assert np.array_equal([1,  0,0, 6], diff_column) or \\\n           np.array_equal([-1, 0,0,-6], diff_column)"}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "prompt": "def convex_hull_measure_area(point_cloud):\n    \"\"\"\n    Take a 3D point_cloud, determines the convex hull around the points and returns the surface area of the convex hull.\n    \"\"\"", "canonical_solution": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "entry_point": "convex_hull_measure_area", "test": "def check(candidate):\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[1,1,0],[1,1,1],[1,0,0],[1,0,1]]\n\n    assert abs(candidate(point_cloud) - 6) < 0.001\n\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[2,1,0],[2,1,1],[2,0,0],[2,0,1]]\n\n    assert abs(candidate(point_cloud) - 10) < 0.001\n"}
{"task_id": "../test_cases/deconvolve_image.ipynb", "prompt": "def deconvolve_image(image, kernel_image):\n    \"\"\"\n    Deconvolve an image with a kernel_image and return the result.\n    \"\"\"", "canonical_solution": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "entry_point": "deconvolve_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,1,0,0,0,0,0],\n        [1,1,1,0,0,0,0],\n        [0,2,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,1,1,1,0],\n        [0,0,0,0,2,0,0],\n    ])\n    kernel= np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,0,2,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n\n    \n    image = np.asarray([\n        [0,1,1,0,0,0,0],\n        [1,2,2,1,0,0,0],\n        [0,2,2,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    assert np.allclose(reference, result)\n   \n"}
{"task_id": "../test_cases/detect_edges.ipynb", "prompt": "def detect_edges(image):\n    \"\"\"\n    Applies an edge-detection filter to an image.\n    \"\"\"", "canonical_solution": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "entry_point": "detect_edges", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n    ])\n\n    result = candidate(image)\n    left_column = result[:,0]\n    center_columns = result[:,1:4]\n    right_column = result[:,-1]\n\n    assert left_column.max() == 0 and left_column.min() == 0\n    assert center_columns.max() != 0 or center_columns.min() != 0\n    assert right_column.max() == 0 and left_column.min() == 0"}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "prompt": "def measure_intensity_over_time(image_list):\n    \"\"\"\n    Takes a timelapse (list of images), measures the average intensity over time and returns the resulting measurements as list.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2))", "entry_point": "measure_intensity_over_time", "test": "def check(candidate):\n    import numpy as np\n\n    images = [\n        np.asarray([[0,1],[1,1]]),\n        np.asarray([[0,2],[2,2]]),\n        np.asarray([[0,3],[3,3]]),\n        np.asarray([[0,3],[2,2]]),\n        np.asarray([[0,2],[2,1]]),\n        np.asarray([[0,1],[1,0]]),\n    ]\n    reference = [0.75, 1.5, 2.25, 7/4, 5/4, 0.5]\n    \n    result = candidate(images) \n\n    assert np.allclose(reference, result, atol=0.001)\n"}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "prompt": "def measure_properties_of_regions(label_image, intensity_image):\n    \"\"\"\n    Takes a label image and an intensity image, and returns pandas dataframe\n    with measurements for area, perimeter and mean_intensity.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "entry_point": "measure_properties_of_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,2],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])\n\n    intensity_image = np.asarray([\n        [0,2,0,0,0],\n        [0,0,0,0,0],\n        [0,3,3,4,4],\n        [0,3,3,0,0],\n        [0,0,0,5,0],\n    ])\n    \n    result = candidate(label_image, intensity_image) \n    \n    assert \"mean_intensity\" in result.columns\n    assert \"area\" in result.columns\n    assert \"perimeter\" in result.columns\n    assert len(result.columns) == 3\n    assert len(result) == 4"}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "prompt": "def open_image_read_voxel_size(image_filename):\n    \"\"\"\n    Reads an image file and return its voxel size in Z-Y-X order.\n    \"\"\"", "canonical_solution": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "entry_point": "open_image_read_voxel_size", "test": "def check(candidate):\n    voxel_size = candidate(\"../example_data/noise.ome.tif\")\n\n    assert voxel_size[0] == 0.5\n    assert voxel_size[1] == 0.2\n    assert voxel_size[2] == 0.2\n\n    voxel_size = candidate(\"../example_data/noise.tif\")\n\n    assert voxel_size[0] == 0.5\n    assert voxel_size[1] == 0.2\n    assert voxel_size[2] == 0.2"}
{"task_id": "../test_cases/open_zarr.ipynb", "prompt": "def open_zarr(zarr_file_location):\n    \"\"\"\n    Opens a zarr file and returns the array\n    \"\"\"", "canonical_solution": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "entry_point": "open_zarr", "test": "def check(candidate):\n    array = candidate(\"../example_data/one-dimensional.zarr\")\n    import numpy as np\n    assert np.all(array == np.arange(10))"}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "prompt": "def subtract_background_tophat(image, radius:int=1):\n    \"\"\"\n    Applies a top-hat filter with a given radius to an image with dark background (low values) and bright foreground (high values).\n    \"\"\"", "canonical_solution": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "entry_point": "subtract_background_tophat", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,1,1,1,1,1,1],\n        [1,2,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,4,1,1,1,1,1],\n        [1,1,1,1,1,1,2,1],\n        [1,1,1,1,1,1,1,1],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,3,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n    assert np.array_equal(candidate(reference), reference)\n\n    # note this test case is kept simple to allow also other top-hat implementations (e.g. with a square footpint) to pass\n"}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "prompt": "def sum_intensity_projection(image):\n    \"\"\"\n    Performs a maximum intensity projection along the first axis of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "entry_point": "sum_intensity_projection", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,3,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,6,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray(\n        [0,5,0,0,9,0]\n    )\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "prompt": "def workflow_segment_measure_umap(image):\n    \"\"\"\n    This function takes a single channel intensity image, \n    segments objects with intensity above half the maximum intensity, \n    labels connected components, \n    measures area, perimeter, mean_intensity, minor and major axis of the labeled objects, \n    and produces a UMAP from the given measurements. \n    The two UMAP vectors are saved as `umap0` and `umap1` togther with the measurements in a dataframe. \n    The function returns this dataframe.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "entry_point": "workflow_segment_measure_umap", "test": "def check(candidate):\n    import numpy as np\n\n    images = np.asarray([\n            [1,0,0,0,1,0,1,1,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n            [1,0,0,0,1,0,1,0,1,0],    \n            [1,0,1,0,0,0,0,0,1,0],    \n            [1,0,0,0,0,0,0,0,0,0],    \n            [1,0,0,1,0,1,1,0,1,0],    \n            [1,0,0,1,0,1,0,0,1,0],    \n            [1,0,0,1,0,0,0,1,1,0],    \n            [1,0,0,0,0,1,0,0,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n        ])\n    \n    result = candidate(images) \n\n    expected_columns = ['area', 'perimeter', 'mean_intensity', \n                        'minor_axis_length', 'major_axis_length',\n                        'umap0', 'umap1']\n\n    # I'm not sure how to check if the umap columns contain a proper umap, \n    # but we can check if all expected columns exist.\n    for ec in expected_columns:\n        assert ec in result.columns"}
