# Generative Artificial Intelligence Notebooks

This page is a collection of Jupyter Notebooks about Generative Artificial Intelligence (GenAI) - focusing on how to use certain techniques using Python. It aims at Python programmers who want to dive into GenAI for generating text, code and images using commerical and open source/weights models.

Contributions and feedback are very welcome! In case you see room for improvement, please [create a github issue](https://github.com/ScaDS/Generative-AI-notebooks/issues) and/or consider [contributing](https://github.com/ScaDS/Generative-AI-notebooks/blob/main/CONTRIBUTING.md).

## Topics

The notebook collection aims covering these topics:
* Large Language Models (LLMs)
* Vision Language Models (VLMs)
* Multi-modal Language Models
* Text/Code/Image generation
* Prompt Engineering
* Retrieval-augmented-generation
* Model fine-tuning
* Variational Auto-Encoders (VAEs)

## Covered Python libraries and software

In these notebooks we use non-standard libraries from the GenAI field. Installation instructions can be found either in the first chapter or in the readme of the respective subchapter.

* [anthropic](https://github.com/anthropics/anthropic-sdk-python)
* [bia-bob](https://github.com/haesleinhuepf/bia-bob)
* [blablado](https://github.com/haesleinhuepf/blablado)
* [blablador](https://helmholtz-blablador.fz-juelich.de/)
* [huggingface_hub](https://github.com/huggingface/huggingface_hub)
* [langchain](https://www.langchain.com/)
* [llama-index](https://www.llamaindex.ai/)
* [ollama](https://ollama.com/)
* [openai](https://github.com/openai/openai-python)
* [pytorch](https://pytorch.org/)
* [pytorch-lightning](https://lightning.ai/docs/pytorch/stable/)
* [torchmetrics](https://lightning.ai/docs/torchmetrics/stable/)
* [transformers](https://github.com/huggingface/transformers)

## Covered models

We will explore how these models work
* [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)
* [Dall-E](https://openai.com/index/dall-e-2/) / [3](https://openai.com/index/dall-e-3/)
* [gemma](https://ollama.com/library/gemma)
* [GPT3.5 / 4  / 4-Omni](https://openai.com/index/hello-gpt-4o/)
* [llava 1.6](https://ollama.com/library/llava),
* [mistral:v0.3](https://ollama.com/library/mistral:v0.3)
* [Pix2pix](https://huggingface.co/timbrooks/instruct-pix2pix)
* [Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)

## Acknowledgements

We acknowledge the financial support by the Federal Ministry of Education and Research of Germany and by Sächsische Staatsministerium für Wissenschaft, Kultur und Tourismus in the programme Center of Excellence for AI-research „Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig“, project identification number: ScaDS.AI

### Related resources

The notebooks presented here were partially taken from other places or inspired by code in these resources:

* https://docs.mistral.ai/capabilities/function_calling/
* https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/
* https://platform.openai.com/docs/guides/images/usage
* https://huggingface.co/stabilityai/stable-diffusion-2-1-base
* https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint
* https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img
* https://github.com/ScaDS/prompting-with-api
* https://github.com/haesleinhuepf/simple-rag
* https://github.com/haesleinhuepf/simple-chat-with-docs
* https://github.com/ScaDS/BIDS-lecture-2024
* https://scads.github.io/prompt-engineering-tutorial-2023/
* https://github.com/haesleinhuepf/prompting-pptx

