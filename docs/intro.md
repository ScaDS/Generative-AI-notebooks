# Generative Artificial Intelligence Notebooks

This page is a collection of Jupyter Notebooks about Generative Artificial Intelligence (GenAI) - focusing on how to use certain techniques using Python. It aims at Python programmers who want to dive into GenAI for generating text, code and images using commerical and open source/weights models.

Contributions and feedback are very welcome! In case you see room for improvement, please [create a github issue](https://github.com/ScaDS/Generative-AI-notebooks/issues) and/or consider [contributing](https://github.com/ScaDS/Generative-AI-notebooks/blob/main/CONTRIBUTING.md).

## Topics

The notebook collection aims covering these topics:
* Large Language Models (LLMs)
* Vision Language Models (VLMs)
* Multi-modal Language Models
* Text/Code/Image generation
* Prompt Engineering
* Retrieval-augmented-generation
* Model fine-tuning

## Covered Python libraries and software

In these notebooks we use non-standard libraries from the GenAI field. Installation instructions can be found either in the first chapter or in the readme of the respective subchapter.

* [anthropic](https://github.com/anthropics/anthropic-sdk-python)
* [autogen](https://github.com/microsoft/autogen)
* [bia-bob](https://github.com/haesleinhuepf/bia-bob)
* [blablado](https://github.com/haesleinhuepf/blablado)
* [blablador](https://helmholtz-blablador.fz-juelich.de/)
* [huggingface_hub](https://github.com/huggingface/huggingface_hub)
* [langchain](https://www.langchain.com/)
* [LangGraph](https://langchain-ai.github.io/langgraph/)
* [llama-index](https://www.llamaindex.ai/)
* [ollama](https://ollama.com/)
* [openai](https://github.com/openai/openai-python)
* [pytorch](https://pytorch.org/)
* [pytorch-lightning](https://lightning.ai/docs/pytorch/stable/)
* [torchmetrics](https://lightning.ai/docs/torchmetrics/stable/)
* [transformers](https://github.com/huggingface/transformers)

## Covered models

We will explore how these models work
* [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)
* [Dall-E](https://openai.com/index/dall-e-2/) / [3](https://openai.com/index/dall-e-3/)
* [gemma](https://ollama.com/library/gemma)
* [GPT3.5 / 4  / 4-Omni](https://openai.com/index/hello-gpt-4o/)
* [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)
* [llava 1.6](https://ollama.com/library/llava),
* [mistral:v0.3](https://ollama.com/library/mistral:v0.3)
* [Pix2pix](https://huggingface.co/timbrooks/instruct-pix2pix)
* [Qwen/Qwen2-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct)
* [Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)

### Videos

The materials provided here were also discussed in a couple of recorded Online Lectures
* [Large Language Models for Bio-image Analysis (ScaDS.AI Living Lab lecture 2024)](https://www.youtube.com/watch?v=9dtVlVwk2eg)
* [Large Language Models – an introduction for life scientists (GloBIAS Seminar 2024)](https://www.youtube.com/watch?v=VbD_zS5GOSc)
* [Bio-image Analysis Code Generation (I2K Conference 2024)](https://www.youtube.com/watch?v=sBcV8rasOWo)
* [Generative Artificial Intelligence for Bio-image Analysis](https://www.youtube.com/watch?v=nC0REzvOT5s)

### Slide decks

Also training slides about LLMs are online open access:
* [Large Language Models for Quantiative Bio-image Analysis (ScaDS.AI Summer School 2024)](https://zenodo.org/records/12518075)
* [Bio-image Data Science Lectures (Uni Leipzig / ScaDS.AI 2024)](https://zenodo.org/records/12623730)
* [Bio-image Analysis with the Help of Large Language Models (Leibnitz IPHT Seminar, Jena, 2024)](https://zenodo.org/records/10815329)
* [Bio-image Analysis using Large Language Models (IMOL Seminar, Frankfurt, 2024)](https://zenodo.org/records/10784549)

### Related resources

The notebooks presented here were partially taken from other places or inspired by code in these resources:

* https://docs.mistral.ai/capabilities/function_calling/
* https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/
* https://platform.openai.com/docs/guides/images/usage
* https://huggingface.co/stabilityai/stable-diffusion-2-1-base
* https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint
* https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img
* https://github.com/ScaDS/prompting-with-api
* https://github.com/haesleinhuepf/simple-rag
* https://github.com/haesleinhuepf/simple-chat-with-docs
* https://github.com/ScaDS/BIDS-lecture-2024
* https://scads.github.io/prompt-engineering-tutorial-2023/
* https://github.com/haesleinhuepf/prompting-pptx


## Acknowledgements

We acknowledge the financial support by the Federal Ministry of Education and Research of Germany and by Sächsische Staatsministerium für Wissenschaft, Kultur und Tourismus in the programme Center of Excellence for AI-research „Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig“, project identification number: ScaDS.AI