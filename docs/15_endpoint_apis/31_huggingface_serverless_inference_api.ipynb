{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb215406-4a08-4462-a8d8-4dfcda16eddb",
   "metadata": {},
   "source": [
    "# Huggingface Serverless Inference \n",
    "\n",
    "You can also access LLMs using [Huggingface Serverless Inference Endpoints](https://huggingface.co/docs/api-inference/index). You will need a huggingface token for this. You can [search for available models](https://huggingface.co/models?inference=warm&sort=trending) and explore the [rate limits](https://huggingface.co/docs/api-inference/rate-limits).\n",
    "\n",
    "We can define such a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57069372-efb5-42c3-b28f-8697c2c8a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_hf_inf(prompt, model=\"google/gemma-7b\"):\n",
    "    import os\n",
    "    from huggingface_hub import InferenceClient\n",
    "    \n",
    "    client = InferenceClient(token=os.environ[\"HF_TOKEN\"])\n",
    "    \n",
    "    return client.text_generation(prompt,\n",
    "        model=model,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        stop_sequences=[\"\\n\\n\"] \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560d01f-8ff7-4790-9d6a-7aa9a48a86a3",
   "metadata": {},
   "source": [
    "And then call it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfefa8f-02d1-4de5-95ac-b0468ba20e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go on a journey. The rabbit decided to go \n",
      "on a journey in order to see how the forest\n",
      "was. The rabbit decided to go on the journey\n",
      "because he was bored. The rabbit went on the\n",
      "journey and saw a bunch of trees. The rabbit \n",
      "saw a bunch of trees and was very scared. The\n",
      "rabbit saw the trees and was scared because the\n",
      "trees could eat him. The rabbit saw the trees \n",
      "and was scared because they were big and scary\n"
     ]
    }
   ],
   "source": [
    "print(prompt_hf_inf(\"\"\"\n",
    "# A story about the rabbit in the forest\n",
    "Once apon a time, the rabbit decided to \n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5797caf1-1080-493e-add8-5d7114ae2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_hf_inf(\"1+3=\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7535ffad-889a-404d-9ede-88865eece728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to be happy. In our quest for happiness, we often get caught up in the external world. We try to keep up with the Joneses, buying the latest gadgets, traveling to exotic destinations, and trying to keep up with the latest fashions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_hf_inf(\"The purpose of life is\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23574fd-d75d-4696-b1cd-1b392d5dee13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
