{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Variational Auto-Encoders (VAEs)\n",
    "\n",
    "Variational Auto-Encoders (VAEs) are a type of generative model that are widely used in machine learning for tasks such as image generation, anomaly detection, and data compression. In this notebook, we will introduce the basic concepts and theory behind VAEs, and provide simple code examples to help you get started with implementing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "VAEs are a type of auto-encoder, which is a neural network used to learn efficient representations of data, typically for the purpose of dimensionality reduction. However, unlike traditional auto-encoders, VAEs are probabilistic models that learn to generate new data points similar to the training data.\n",
    "\n",
    "The key idea behind VAEs is to learn a latent space representation of the data, which is a lower-dimensional space that captures the essential features of the data. This latent space is then used to generate new data points by sampling from a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "The VAE consists of two main components: the encoder and the decoder. The encoder maps the input data to a latent space, while the decoder maps the latent space back to the original data space.\n",
    "\n",
    "The encoder is typically a neural network that takes the input data and outputs the parameters of a probability distribution in the latent space. The decoder is another neural network that takes samples from this distribution and generates new data points.\n",
    "\n",
    "The training of a VAE involves maximizing the likelihood of the data under the model, which is done by minimizing a loss function that consists of two terms: the reconstruction loss and the KL divergence. The reconstruction loss measures how well the decoder can reconstruct the input data from the latent space, while the KL divergence measures how close the learned distribution is to a prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Example\n",
    "\n",
    "Let's start with a simple implementation of a VAE using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Encoder\n",
    "\n",
    "The encoder network takes the input data and outputs the parameters of the latent distribution (mean and log variance)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        mean = self.fc2_mean(h)\n",
    "        log_var = self.fc2_log_var(h)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Decoder\n",
    "\n",
    "The decoder network takes samples from the latent distribution and generates new data points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, z):\n",
    "        h = self.relu(self.fc1(z))\n",
    "        x_reconstructed = self.sigmoid(self.fc2(h))\n",
    "        return x_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the VAE\n",
    "\n",
    "The VAE model combines the encoder and decoder, and includes a sampling layer to sample from the latent distribution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = mean + std * epsilon\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Loss Function\n",
    "\n",
    "The loss function consists of the reconstruction loss and the KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def vae_loss(x, x_reconstructed, mean, log_var):\n",
    "    reconstruction_loss = nn.functional.binary_cross_entropy(x_reconstructed, x, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return reconstruction_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the VAE\n",
    "\n",
    "Let's train the VAE on a simple dataset, such as the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the VAE model\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 256\n",
    "latent_dim = 2\n",
    "encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for x, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, mean, log_var = vae(x)\n",
    "        loss = vae_loss(x, x_reconstructed, mean, log_var)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss / len(train_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Results\n",
    "\n",
    "Let's visualize the latent space learned by the VAE and generate some new data points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Encode the test data to the latent space\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    z_mean, z_log_var = [], []\n",
    "    for x, _ in test_loader:\n",
    "        mean, log_var = vae.encoder(x)\n",
    "        z_mean.append(mean)\n",
    "        z_log_var.append(log_var)\n",
    "    z_mean = torch.cat(z_mean)\n",
    "    z_log_var = torch.cat(z_log_var)\n",
    "    z = z_mean + torch.exp(0.5 * z_log_var) * torch.randn_like(z_mean)\n",
    "\n",
    "# Plot the latent space\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(z[:, 0].numpy(), z[:, 1].numpy(), c='blue', alpha=0.5)\n",
    "plt.xlabel('z1')\n",
    "plt.ylabel('z2')\n",
    "plt.title('Latent Space')\n",
    "plt.show()\n",
    "\n",
    "# Generate new data points\n",
    "z_new = torch.randn(10, latent_dim)\n",
    "with torch.no_grad():\n",
    "    generated = vae.decoder(z_new)\n",
    "\n",
    "# Plot the generated data points\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(generated[i].view(28, 28).numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ]
}
